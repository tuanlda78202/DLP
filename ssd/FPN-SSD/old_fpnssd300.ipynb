{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:54:59.540973Z","iopub.status.busy":"2022-12-30T05:54:59.540612Z","iopub.status.idle":"2022-12-30T05:55:02.391022Z","shell.execute_reply":"2022-12-30T05:55:02.389838Z","shell.execute_reply.started":"2022-12-30T05:54:59.540895Z"},"id":"GS2lmn1E5FSl","trusted":true},"outputs":[],"source":["from torchvision.datasets import VOCDetection\n","from utils.utils import *\n","from models.fpnssd300 import SSD300\n","from data.dataset import VOCDataset\n","from detect import detect\n","\n","from pprint import PrettyPrinter\n","from tqdm import tqdm\n","from pprint import pprint\n","\n","import numpy as np\n","from numpy import random\n","from torchinfo import summary\n","\n","import pandas as pd\n","import cv2\n","import os\n","import os.path as osp\n","import time\n","import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import torchvision.transforms.functional as FT\n","\n","from math import sqrt\n","from sklearn import preprocessing \n","from torch.utils.data import DataLoader, Dataset\n","\n","import torch\n","from torchvision import transforms\n","import types\n","import torchvision\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from PIL import Image, ImageDraw"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:55:02.401093Z","iopub.status.busy":"2022-12-30T05:55:02.397926Z","iopub.status.idle":"2022-12-30T05:57:37.002085Z","shell.execute_reply":"2022-12-30T05:57:37.001080Z","shell.execute_reply.started":"2022-12-30T05:55:02.401053Z"},"id":"Ww6uqJ1o5Mvs","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to data/VOCtrainval_11-May-2012.tar\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"707794820e234a38b8c6b6cf88faad5f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1999639040 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting data/VOCtrainval_11-May-2012.tar to data/\n","Using downloaded and verified file: data/VOCtrainval_11-May-2012.tar\n","Extracting data/VOCtrainval_11-May-2012.tar to data/\n"]}],"source":["dataset = VOCDetection(root='data/',year ='2012', image_set='train', download=True)\n","\n","test_dataset = VOCDetection(root='data/', year = '2012',image_set='val', download=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rev_label_map= {0: 'background',\n","                1:'aeroplane',\n","              2:'bicycle',\n","              3:'bird',\n","              4:'boat',\n","              5:'bottle',\n","              6:'bus',\n","              7:'car',\n","              8:'cat',\n","              9:'chair',\n","              10:'cow',\n","              11:'diningtable',\n","              12:'dog',\n","              13:'horse',\n","              14:'motorbike',\n","              15:'person',\n","              16:'pottedplant',\n","              17:'sheep',\n","              18:'sofa',\n","              19:'train',\n","              20:'tvmonitor'}\n","\n","label_map = {v: k for k, v in rev_label_map.items() if k!= 0}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-29T14:30:45.872494Z","iopub.status.busy":"2022-12-29T14:30:45.872100Z","iopub.status.idle":"2022-12-29T14:30:45.879618Z","shell.execute_reply":"2022-12-29T14:30:45.878567Z","shell.execute_reply.started":"2022-12-29T14:30:45.872454Z"},"id":"RW_R7J4e5gFi","outputId":"a33a2209-ba86-4117-91bc-1c267c682894","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["5717 5823\n"]}],"source":["print(len(dataset), len(test_dataset))"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:57:37.004979Z","iopub.status.busy":"2022-12-30T05:57:37.003691Z","iopub.status.idle":"2022-12-30T05:57:37.013563Z","shell.execute_reply":"2022-12-30T05:57:37.012660Z","shell.execute_reply.started":"2022-12-30T05:57:37.004913Z"},"id":"FdVv-AWFGSOF","trusted":true},"outputs":[],"source":["def image_dict(split):\n","    image_dict = {}\n","    if split == \"train\":\n","        for image_info in dataset:\n","            image = image_info[0]\n","            image_id = image_info[1]['annotation']['filename'].split(\".\")[0]\n","            image_dict[image_id] = image\n","    if split == \"test\":\n","        for image_info in test_dataset:\n","            image = image_info[0]\n","            image_id = image_info[1]['annotation']['filename'].split(\".\")[0]\n","            image_dict[image_id] = image\n","    return image_dict"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:57:37.017529Z","iopub.status.busy":"2022-12-30T05:57:37.017280Z","iopub.status.idle":"2022-12-30T05:58:40.899060Z","shell.execute_reply":"2022-12-30T05:58:40.897932Z","shell.execute_reply.started":"2022-12-30T05:57:37.017505Z"},"id":"h1kmMbVmHt-p","trusted":true},"outputs":[],"source":["train_image_dict = image_dict(\"train\")\n","test_image_dict = image_dict(\"test\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:59:58.224164Z","iopub.status.busy":"2022-12-30T05:59:58.223793Z","iopub.status.idle":"2022-12-30T05:59:58.255907Z","shell.execute_reply":"2022-12-30T05:59:58.254981Z","shell.execute_reply.started":"2022-12-30T05:59:58.224130Z"},"id":"XCWl4WMkCece","trusted":true},"outputs":[],"source":["df_train = pd.read_csv(\"data/train_voc_pascal12.csv/working/train_voc_pascal12.csv\")\n","df_test = pd.read_csv(\"data/test_voc_pascal12.csv/working/test_voc_pascal12.csv\")"]},{"cell_type":"markdown","metadata":{"id":"E2w17NlvDZep"},"source":["## Create the dataset"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:59:58.325096Z","iopub.status.busy":"2022-12-30T05:59:58.324595Z","iopub.status.idle":"2022-12-30T05:59:58.343201Z","shell.execute_reply":"2022-12-30T05:59:58.341996Z","shell.execute_reply.started":"2022-12-30T05:59:58.325027Z"},"id":"NTTGwxobJaAz","trusted":true},"outputs":[],"source":["keep_difficult = True\n","train_dataset = VOCDataset(df_train, train_image_dict, \"TRAIN\",keep_difficult)\n","test_dataset = VOCDataset(df_test, test_image_dict, \"TEST\",keep_difficult)\n","\n","# del train_image_dict, test_image_dict\n","# del df_train, df_test"]},{"cell_type":"markdown","metadata":{"id":"TZe6CgRuKXTa"},"source":["## Dataloader "]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:59:58.347079Z","iopub.status.busy":"2022-12-30T05:59:58.345351Z","iopub.status.idle":"2022-12-30T05:59:58.353146Z","shell.execute_reply":"2022-12-30T05:59:58.352127Z","shell.execute_reply.started":"2022-12-30T05:59:58.347044Z"},"id":"HYEaBFIuKT9P","trusted":true},"outputs":[],"source":["# split the dataset in train and test set\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=2,\n","    collate_fn=train_dataset.collate_fn\n",")\n","\n","test_data_loader = DataLoader(\n","    test_dataset,\n","    batch_size=16,\n","    shuffle=False,\n","    num_workers=2,\n","    collate_fn=test_dataset.collate_fn\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T05:59:58.354872Z","iopub.status.busy":"2022-12-30T05:59:58.354417Z","iopub.status.idle":"2022-12-30T05:59:58.366652Z","shell.execute_reply":"2022-12-30T05:59:58.365728Z","shell.execute_reply.started":"2022-12-30T05:59:58.354822Z"},"id":"tQ2lhUyPKT6y","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training iterations:  358\n","Number of testing iterations:  364\n"]}],"source":["print(\"Number of training iterations: \", len(train_data_loader))\n","print(\"Number of testing iterations: \", len(test_data_loader))"]},{"cell_type":"markdown","metadata":{"id":"dzdJsV5eLCf8"},"source":["# MODEL"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T06:00:02.297352Z","iopub.status.busy":"2022-12-30T06:00:02.296642Z","iopub.status.idle":"2022-12-30T06:00:02.407377Z","shell.execute_reply":"2022-12-30T06:00:02.406371Z","shell.execute_reply.started":"2022-12-30T06:00:02.297300Z"},"id":"gnMYglEvKT1R","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on device cuda\n"]}],"source":["device = (torch.device('cuda') if torch.cuda.is_available()\n","          else torch.device('cpu'))\n","print(f\"Training on device {device}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T06:00:17.784519Z","iopub.status.busy":"2022-12-30T06:00:17.784111Z","iopub.status.idle":"2022-12-30T06:00:30.005397Z","shell.execute_reply":"2022-12-30T06:00:30.004353Z","shell.execute_reply.started":"2022-12-30T06:00:17.784482Z"},"id":"01nyLVIJLSmT","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd8d11549b6f47a2a1e6f40c8a575a7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"]},{"data":{"text/plain":["====================================================================================================\n","Layer (type:depth-idx)                             Output Shape              Param #\n","====================================================================================================\n","SSD300                                             [16, 8532, 4]             256\n","├─FPNBase: 1-1                                     [16, 256, 38, 38]         --\n","│    └─ResNet: 2-1                                 --                        2,049,000\n","│    │    └─Conv2d: 3-1                            [16, 64, 150, 150]        9,408\n","│    │    └─BatchNorm2d: 3-2                       [16, 64, 150, 150]        128\n","│    │    └─Sequential: 3-3                        [16, 256, 75, 75]         215,808\n","│    │    └─Sequential: 3-4                        [16, 512, 38, 38]         1,219,584\n","│    │    └─Sequential: 3-5                        [16, 1024, 19, 19]        7,098,368\n","│    │    └─Sequential: 3-6                        [16, 2048, 10, 10]        14,964,736\n","│    └─Conv2d: 2-2                                 [16, 256, 5, 5]           4,718,848\n","│    └─BatchNorm2d: 2-3                            [16, 256, 5, 5]           512\n","│    └─Conv2d: 2-4                                 [16, 256, 3, 3]           590,080\n","│    └─BatchNorm2d: 2-5                            [16, 256, 3, 3]           512\n","│    └─Conv2d: 2-6                                 [16, 256, 2, 2]           590,080\n","│    └─BatchNorm2d: 2-7                            [16, 256, 2, 2]           512\n","│    └─Conv2d: 2-8                                 [16, 256, 1, 1]           590,080\n","│    └─Conv2d: 2-9                                 [16, 256, 8, 8]           4,718,848\n","│    └─Conv2d: 2-10                                [16, 256, 19, 19]         262,400\n","│    └─Conv2d: 2-11                                [16, 256, 38, 38]         131,328\n","│    └─Conv2d: 2-12                                [16, 256, 19, 19]         590,080\n","│    └─Conv2d: 2-13                                [16, 256, 38, 38]         590,080\n","├─PredictionConvolutions: 1-2                      [16, 8532, 4]             --\n","│    └─Conv2d: 2-14                                [16, 16, 38, 38]          36,880\n","│    └─Conv2d: 2-15                                [16, 24, 19, 19]          55,320\n","│    └─Conv2d: 2-16                                [16, 24, 8, 8]            55,320\n","│    └─Conv2d: 2-17                                [16, 24, 5, 5]            55,320\n","│    └─Conv2d: 2-18                                [16, 16, 3, 3]            36,880\n","│    └─Conv2d: 2-19                                [16, 16, 2, 2]            36,880\n","│    └─Conv2d: 2-20                                [16, 16, 1, 1]            36,880\n","│    └─Conv2d: 2-21                                [16, 84, 38, 38]          193,620\n","│    └─Conv2d: 2-22                                [16, 126, 19, 19]         290,430\n","│    └─Conv2d: 2-23                                [16, 126, 8, 8]           290,430\n","│    └─Conv2d: 2-24                                [16, 126, 5, 5]           290,430\n","│    └─Conv2d: 2-25                                [16, 84, 3, 3]            193,620\n","│    └─Conv2d: 2-26                                [16, 84, 2, 2]            193,620\n","│    └─Conv2d: 2-27                                [16, 84, 1, 1]            193,620\n","====================================================================================================\n","Total params: 40,299,898\n","Trainable params: 40,299,898\n","Non-trainable params: 0\n","Total mult-adds (G): 158.32\n","====================================================================================================\n","Input size (MB): 17.28\n","Forward/backward pass size (MB): 5348.14\n","Params size (MB): 153.00\n","Estimated Total Size (MB): 5518.42\n","===================================================================================================="]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["model = SSD300(n_classes = 21)\n","summary(model, (16, 3, 300, 300))"]},{"cell_type":"markdown","metadata":{"id":"ncAmyoh4Lauq"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqzQkeOZLSa2","trusted":true},"outputs":[],"source":["# Data parameters\n","data_folder = './'  # folder with data files\n","\n","# Model parameters\n","# Not too many here since the SSD300 has a very specific structure\n","n_classes = len(label_map)  # number of different types of objects\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Learning parameters\n","checkpoint = \"..\\checkpoint\\checkpoint_ssd300_280.pth.tar\"  # path to model checkpoint, None if none\n","batch_size = 16  # batch size\n","iterations = 100000  # number of iterations to train\n","# workers = 4  # number of workers for loading data in the DataLoader\n","print_freq = 50  # print training status every __ batches\n","lr = 5e-4  # learning rate\n","decay_lr_at = [60000, 80000]  # decay learning rate after these many iterations\n","decay_lr_to = 0.1  # decay learning rate to this fraction of the existing learning rate\n","momentum = 0.9  # momentum\n","weight_decay = 5e-4  # weight decay\n","grad_clip = 1  # clip if gradients are exploding, which may happen at larger batch sizes (sometimes at 32) - you will recognize it by a sorting error in the MuliBox loss calculation\n","\n","\n","def main():\n","    \"\"\"\n","    Training.\n","    \"\"\"\n","    global start_epoch, label_map, epoch, checkpoint, decay_lr_at\n","\n","    # Initialize model or load checkpoint\n","    if checkpoint is None:\n","        start_epoch = 0\n","        model = SSD300(n_classes = 21)\n","        for index, child in enumerate(model.base.resnet.children()):\n","            if index != 7:\n","                for param in child.parameters():\n","                    param.requires_grad = False\n","        # Initialize the optimizer, with twice the default learning rate for biases, as in the original Caffe repo\n","        biases = list()\n","        not_biases = list()\n","        for param_name, param in model.named_parameters():\n","            if param.requires_grad:\n","                if param_name.endswith('.bias'):\n","                    biases.append(param)\n","                else:\n","                    not_biases.append(param)\n","        optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': 2 * lr}, {'params': not_biases}],\n","                                    lr=lr, momentum = momentum, weight_decay=weight_decay)\n","\n","    else:\n","        checkpoint = torch.load(checkpoint)\n","        start_epoch = checkpoint['epoch'] + 1\n","        print('\\nLoaded checkpoint from epoch %d.\\n' % start_epoch)\n","        model = checkpoint['model']\n","        optimizer = checkpoint['optimizer']\n","\n","    # Move to default device\n","    model = model.to(device)\n","    criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)\n","\n","    # Calculate total number of epochs to train and the epochs to decay learning rate at (i.e. convert iterations to epochs)\n","    # To convert iterations to epochs, divide iterations by the number of iterations per epoch\n","    # The paper trains for 120,000 iterations with a batch size of 32, decays after 80,000 and 100,000 iterations\n","    epochs = iterations // (len(train_dataset) // 16)\n","    print(\"Number of epochs: \", epochs)\n","    decay_lr_at = [it // (len(train_dataset) // 16) for it in decay_lr_at]\n","    \n","    # Epochs\n","    for epoch in range(start_epoch, epochs):\n","\n","        # Decay learning rate at particular epochs\n","        if epoch in decay_lr_at:\n","            adjust_learning_rate(optimizer, decay_lr_to)\n","\n","        # One epoch's training\n","        train(train_loader=train_data_loader,\n","              model=model,\n","              criterion=criterion,\n","              optimizer=optimizer,\n","              epoch=epoch)\n","\n","        # Save checkpoint\n","        print(\"Saving checkpoint epoch:\", epoch)\n","        save_checkpoint(epoch, model, optimizer)\n","\n","\n","def train(train_loader, model, criterion, optimizer, epoch):\n","    \"\"\"\n","    One epoch's training.\n","    :param train_loader: DataLoader for training data\n","    :param model: model\n","    :param criterion: MultiBox loss\n","    :param optimizer: optimizer\n","    :param epoch: epoch number\n","    \"\"\"\n","    model.train()  # training mode enables dropout\n","\n","    losses = AverageMeter()  # loss\n","\n","\n","    # Batches\n","    for i, (images, boxes, labels, _) in enumerate(train_loader):\n","        \n","        start = time.time()\n","        \n","        # Move to default device\n","        images = images.to(device)  # (batch_size (N), 3, 300, 300)\n","        boxes = [b.to(device) for b in boxes]\n","        labels = [l.to(device) for l in labels]\n","\n","        # Forward prop.\n","        predicted_locs, predicted_scores = model(images)  # (N, 8732, 4), (N, 8732, n_classes)\n","\n","        # Loss\n","        loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n","\n","        # Backward prop.\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # Clip gradients, if necessary\n","        if grad_clip is not None:\n","            clip_gradient(optimizer, grad_clip)\n","\n","        # Update model\n","        optimizer.step()\n","\n","        losses.update(loss.item(), images.size(0))\n","\n","        # Print status\n","        if i % print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Training Time {3:.3f} \\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(train_loader),\n","                                                                  (time.time()-start)*print_freq, loss=losses))\n","    \n","    if epoch % 10 == 0:\n","        model.eval()\n","        val_losses = AverageMeter()\n","\n","        with torch.no_grad():\n","            # Batches\n","            for i, (images, boxes, labels, difficulties) in enumerate(test_data_loader):\n","                images = images.to(device)  # (batch_size (N), 3, 300, 300)\n","                boxes = [b.to(device) for b in boxes]\n","                labels = [l.to(device) for l in labels]\n","\n","                # Forward prop.\n","                predicted_locs, predicted_scores = model(images)  # (N, 8732, 4), (N, 8732, n_classes)\n","\n","                # Loss\n","                loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n","\n","                val_losses.update(loss.item(), images.size(0))\n","\n","            # Print status\n","            print('Validation loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(loss=val_losses))\n","    del predicted_locs, predicted_scores, images, boxes, labels  # free some memory since their histories may be stored\n","\n","main()"]},{"cell_type":"markdown","metadata":{"id":"T1SCFeF_LkAe"},"source":["## Calculating mAP"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T06:45:22.758330Z","iopub.status.busy":"2022-12-30T06:45:22.757997Z","iopub.status.idle":"2022-12-30T06:45:22.764269Z","shell.execute_reply":"2022-12-30T06:45:22.763200Z","shell.execute_reply.started":"2022-12-30T06:45:22.758303Z"},"trusted":true},"outputs":[],"source":["# Good formatting when printing the APs for each class and mAP\n","pp = PrettyPrinter()"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T07:03:55.362190Z","iopub.status.busy":"2022-12-30T07:03:55.361355Z","iopub.status.idle":"2022-12-30T07:09:24.706463Z","shell.execute_reply":"2022-12-30T07:09:24.705110Z","shell.execute_reply.started":"2022-12-30T07:03:55.362139Z"},"id":"0GSHs5pBLSVW","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating:   0%|          | 0/364 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:173: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/IndexingUtils.h:27.)\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:175: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/IndexingUtils.h:27.)\n","Evaluating: 100%|██████████| 364/364 [03:35<00:00,  1.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["{'aeroplane': 0.7581235766410828,\n"," 'bicycle': 0.7262179851531982,\n"," 'bird': 0.6922540068626404,\n"," 'boat': 0.4577009677886963,\n"," 'bottle': 0.3729631304740906,\n"," 'bus': 0.7464362382888794,\n"," 'car': 0.5342469215393066,\n"," 'cat': 0.8741917610168457,\n"," 'chair': 0.46735140681266785,\n"," 'cow': 0.6185383796691895,\n"," 'diningtable': 0.5899243950843811,\n"," 'dog': 0.8436293601989746,\n"," 'horse': 0.7462180852890015,\n"," 'motorbike': 0.725793719291687,\n"," 'person': 0.6655958890914917,\n"," 'pottedplant': 0.3164544105529785,\n"," 'sheep': 0.5664616823196411,\n"," 'sofa': 0.6055200099945068,\n"," 'train': 0.7921307682991028}\n","\n","Mean Average Precision (mAP): 0.637\n"]}],"source":["# Parameters\n","data_folder = './'\n","batch_size = 16\n","workers = 2\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","checkpoint = \"..\\checkpoint\\checkpoint_ssd300_280.pth.tar\"\n","\n","# Load model checkpoint that is to be evaluated\n","checkpoint = torch.load(checkpoint)\n","model = checkpoint['model']\n","model = model.to(device)\n","\n","# Switch to eval mode\n","model.eval()\n","\n","def evaluate(test_loader, model):\n","    \"\"\"\n","    Evaluate.\n","    :param test_loader: DataLoader for test data\n","    :param model: model\n","    \"\"\"\n","\n","    # Make sure it's in eval mode\n","    model.eval()\n","\n","    # Lists to store detected and true boxes, labels, scores\n","    det_boxes = list()\n","    det_labels = list()\n","    det_scores = list()\n","    true_boxes = list()\n","    true_labels = list()\n","    true_difficulties = list()  # it is necessary to know which objects are 'difficult', see 'calculate_mAP' in utils.py\n","\n","    with torch.no_grad():\n","        # Batches\n","        for i, (images, boxes, labels, difficulties) in enumerate(tqdm(test_loader, desc='Evaluating')):\n","            images = images.to(device)  # (N, 3, 300, 300)\n","\n","            # Forward prop.\n","            predicted_locs, predicted_scores = model(images)\n","\n","            # Detect objects in SSD output\n","            det_boxes_batch, det_labels_batch, det_scores_batch = model.detect_objects(predicted_locs, predicted_scores,\n","                                                                                       min_score=0.01, max_overlap=0.45,\n","                                                                                       top_k=200)\n","            # Store this batch's results for mAP calculation\n","            boxes = [b.to(device) for b in boxes]\n","            labels = [l.to(device) for l in labels]\n","            difficulties = [d.to(device) for d in difficulties]\n","\n","            det_boxes.extend(det_boxes_batch)\n","            det_labels.extend(det_labels_batch)\n","            det_scores.extend(det_scores_batch)\n","            true_boxes.extend(boxes)\n","            true_labels.extend(labels)\n","            true_difficulties.extend(difficulties)\n","\n","        # Calculate mAP\n","        APs, mAP = calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels, true_difficulties, 0.5)\n","\n","    # Print AP for each class\n","    pp.pprint(APs)\n","\n","    print('\\nMean Average Precision (mAP): %.3f' % mAP)\n","\n","\n","if __name__ == '__main__':\n","    evaluate(test_data_loader, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["id = ['2008_000090', '2008_000107', '2008_000115', '2008_000116', '2008_000119', '2008_000120', '2008_000123', '2008_000133', '2008_000134', '2008_000138', '2008_000140', '2008_000145', '2008_000149', '2008_000163', '2008_000174', '2008_000177', '2008_000182', '2008_000183', '2008_000190', '2008_000194', '2008_000195', '2008_000203', '2008_000204', '2008_000213', '2008_000215', '2008_000219', '2008_000222']\n","for id in id:\n","    original_image = test_image_dict[id]\n","    original_image = original_image.convert('RGB')\n","    detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"}}},"nbformat":4,"nbformat_minor":4}
