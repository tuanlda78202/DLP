{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq1HS5fIFkWS",
        "outputId": "92014063-6d22-4843-855c-31d6ab7e3bb9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Please move to IV to continue training"
      ],
      "metadata": {
        "id": "PV4UhYcjuIAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Install requirements and import library\n"
      ],
      "metadata": {
        "id": "AUzVoyls_kQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install webcolors\n",
        "!pip install split-folders"
      ],
      "metadata": {
        "id": "LZI0SwboFmGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f4dd04-a4d3-4fb6-9d2c-55b22ac61ffb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting webcolors\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: webcolors\n",
            "Successfully installed webcolors-1.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import splitfolders\n",
        "import shutil\n",
        "import json"
      ],
      "metadata": {
        "id": "u4Wb_9He_o3y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Split training, val, test set and convert PASCAL VOC format into COCO format."
      ],
      "metadata": {
        "id": "yoBEYArL_soA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "clone tool for convert pascal voc into coco format"
      ],
      "metadata": {
        "id": "7L-S3W09_zi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cài đặt và import thư viện"
      ],
      "metadata": {
        "id": "m8SHGWaiDYs2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iR5kB01f9x5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3e1dd1-304a-42a2-dfa8-52485f923a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'voc2coco'...\n",
            "remote: Enumerating objects: 381, done.\u001b[K\n",
            "remote: Counting objects: 100% (381/381), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 381 (delta 359), reused 376 (delta 359), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (381/381), 127.61 KiB | 21.27 MiB/s, done.\n",
            "Resolving deltas: 100% (359/359), done.\n"
          ]
        }
      ],
      "source": [
        "# Download source code.\n",
        "if \"voc2coco\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/yukkyo/voc2coco\n",
        "  os.chdir('/content/voc2coco')\n",
        "  sys.path.append('.')\n",
        "else:\n",
        "  !git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Download and split data"
      ],
      "metadata": {
        "id": "sB-uHV99_9_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download data"
      ],
      "metadata": {
        "id": "LgenpMdM_-Ko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WXagP7Kt-wxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a640c2-834d-4147-cf5a-af502c383c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-30 15:45:05--  http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1999639040 (1.9G) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_11-May-2012.tar’\n",
            "\n",
            "VOCtrainval_11-May- 100%[===================>]   1.86G  11.8MB/s    in 2m 43s  \n",
            "\n",
            "2022-12-30 15:47:49 (11.7 MB/s) - ‘VOCtrainval_11-May-2012.tar’ saved [1999639040/1999639040]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download and unzip dataset\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
        "!tar xf VOCtrainval_11-May-2012.tar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split data into 3 part: training set, validation set and test set"
      ],
      "metadata": {
        "id": "F52HSf5KDutS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Oqf2lCZV_1Rb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82ea7c4-081f-41f1-f075-b7a9f4500b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 40076 files [00:11, 3629.32 files/s]\n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio('/content/voc2coco/VOCdevkit/VOC2012', output=\"dataset\", seed=42, ratio=(.6, .2, .2)) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Convert PASCAL VOC format into COCO format.\n",
        "\n",
        "\n",
        "To use tools , we need to reformat the structure to use tools, see detail in here: https://github.com/yukkyo/voc2coco"
      ],
      "metadata": {
        "id": "9DyP_HZCAUuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/voc2coco/sample/Annotations\n",
        "!mkdir /content/voc2coco/sample/Annotations"
      ],
      "metadata": {
        "id": "srnugqEwAQU_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "move file and write .txt file"
      ],
      "metadata": {
        "id": "do9ufqe3AZxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/voc2coco/VOCdevkit/VOC2012/Annotations'\n",
        "for filename in os.listdir(path):\n",
        "    fullname = os.path.join(path, filename)\n",
        "    shutil.move(fullname, '/content/voc2coco/sample/Annotations')  "
      ],
      "metadata": {
        "id": "e6ewmmwgAQek"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/voc2coco/sample/dataset_ids/train.txt','w') as f:\n",
        "    list_train = [i[:-4] for i in os.listdir('/content/voc2coco/dataset/train/Annotations')]\n",
        "    for i in list_train:\n",
        "        f.write(i)\n",
        "        f.write('\\n')\n",
        "\n",
        "with open('/content/voc2coco/sample/dataset_ids/val.txt','w') as f:\n",
        "    list_train = [i[:-4] for i in os.listdir('/content/voc2coco/dataset/val/Annotations')]\n",
        "    for i in list_train:\n",
        "        f.write(i)\n",
        "        f.write('\\n')\n",
        "\n",
        "with open('/content/voc2coco/sample/dataset_ids/test.txt','w') as f:\n",
        "    list_train = [i[:-4] for i in os.listdir('/content/voc2coco/dataset/test/Annotations')]\n",
        "    for i in list_train:\n",
        "        f.write(i)\n",
        "        f.write('\\n')\n",
        "\n",
        "with open('/content/voc2coco/sample/annpaths_list.txt','w') as f:\n",
        "    for i in os.listdir('/content/voc2coco/sample/Annotations'):\n",
        "        f.write('./sample/Annotations/' + i)\n",
        "        f.write('\\n')\n",
        "\n",
        "with open('/content/voc2coco/sample/annpaths_list.txt','w') as f:\n",
        "    for i in os.listdir('/content/voc2coco/sample/Annotations'):\n",
        "        f.write('./sample/Annotations/' + i)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "PcErhjz3AQjn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write label to labets.txt"
      ],
      "metadata": {
        "id": "PYmyNTn5Ajyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object_list = ['aeroplane','bicycle','bird','boat',\\\n",
        "               'bottle','bus','car','cat','chair','cow','diningtable',\\\n",
        "               'dog','horse','motorbike','person'\\\n",
        "               ,'pottedplant','sheep','sofa','train','tvmonitor']\n",
        "\n",
        "\n",
        "with open('/content/voc2coco/sample/labels.txt','w') as f:\n",
        "    for i in object_list:\n",
        "        f.write(i)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "b1tVdsSpAgto"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "start convert pascal voc format into coco format."
      ],
      "metadata": {
        "id": "g1aU6lgwAmRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert for training set\n",
        "!python voc2coco.py --ann_dir sample/Annotations \\\n",
        "    --ann_ids sample/dataset_ids/train.txt \\\n",
        "    --labels sample/labels.txt \\\n",
        "    --output sample/instances_train.json \\\n",
        "    --ext xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us_81GldAgwy",
        "outputId": "52a7f239-b8f4-4320-8adc-b652e7e440e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start converting !\n",
            "100% 10275/10275 [00:00<00:00, 11892.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert for validation set \n",
        "!python voc2coco.py --ann_dir sample/Annotations \\\n",
        "    --ann_ids sample/dataset_ids/val.txt \\\n",
        "    --labels sample/labels.txt \\\n",
        "    --output sample/instances_val.json \\\n",
        "    --ext xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zybitb1cAuhC",
        "outputId": "9c37531f-59a7-4850-d352-954b00ac500b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start converting !\n",
            "100% 3425/3425 [00:00<00:00, 12110.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert for test set\n",
        "!python voc2coco.py --ann_dir sample/Annotations \\\n",
        "    --ann_ids sample/dataset_ids/test.txt \\\n",
        "    --labels sample/labels.txt \\\n",
        "    --output sample/instances_test.json \\\n",
        "    --ext xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo9YqFZJAukf",
        "outputId": "6d7fd3b9-d915-4b3a-89fb-594f15b41333"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start converting !\n",
            "100% 3425/3425 [00:00<00:00, 13046.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we done convert format."
      ],
      "metadata": {
        "id": "cPfoifhvA4Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. Clone tool for training model and processing for right format.\n",
        "\n",
        "See detail: https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch"
      ],
      "metadata": {
        "id": "Bdt932m-A8DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "\n",
        "if \"projects\" not in os.getcwd():\n",
        "  !git clone --depth 1 https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
        "  os.chdir('/content/Yet-Another-EfficientDet-Pytorch')\n",
        "  sys.path.append('.')\n",
        "else:\n",
        "  !git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLJ55aTPAunF",
        "outputId": "417d3704-b1bd-4e9f-ff31-e2f8c9f6b7c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Yet-Another-EfficientDet-Pytorch'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 47 (delta 3), reused 24 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets\n",
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets/voc\n",
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/train\n",
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/val\n",
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/test   \n",
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations"
      ],
      "metadata": {
        "id": "ai1xngi_Agzz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "move the file to the right location"
      ],
      "metadata": {
        "id": "OP63wgo1BFxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/voc2coco/dataset/train/JPEGImages'\n",
        "for filename in os.listdir(path):\n",
        "    fullname = os.path.join(path,filename)\n",
        "    shutil.move(fullname, \"/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/train\") \n",
        "\n",
        "path = '/content/voc2coco/dataset/val/JPEGImages'\n",
        "for filename in os.listdir(path):\n",
        "    fullname = os.path.join(path,filename)\n",
        "    shutil.move(fullname, \"/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/val\") \n",
        "\n",
        "path = '/content/voc2coco/dataset/test/JPEGImages'\n",
        "for filename in os.listdir(path):\n",
        "    fullname = os.path.join(path,filename)\n",
        "    shutil.move(fullname, \"/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/test\") \n",
        "\n",
        "path1 = '/content/voc2coco/sample/instances_train.json'\n",
        "path2 = '/content/voc2coco/sample/instances_val.json'\n",
        "path3 = '/content/voc2coco/sample/instances_test.json'\n",
        "\n",
        "shutil.move(path1, '/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations')\n",
        "shutil.move(path2, '/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations')\n",
        "shutil.move(path3, '/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8QL_Oca9BCP6",
        "outputId": "29cd574f-60c8-4ea6-bd79-52b33dbe1c6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_test.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "because the type of id is string, so we need to convert it into integer."
      ],
      "metadata": {
        "id": "gzdU9r35BNnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_id(path):\n",
        "  f = open(path)\n",
        "  data = json.load(f)\n",
        "\n",
        "  for i in range(len(data['images'])):\n",
        "      value = data['images'][i]['id']\n",
        "      value1 = value[:4] + value[5:]\n",
        "      data['images'][i]['id'] = int(value1)\n",
        "  \n",
        "  for i in range(len(data['annotations'])):\n",
        "      value = data['annotations'][i]['image_id']\n",
        "      value1 = value[:4] + value[5:]\n",
        "      data['annotations'][i]['image_id'] = int(value1)\n",
        "\n",
        "  !rm -rf path\n",
        "  with open(path, 'w') as f:\n",
        "    f.write(json.dumps(data))"
      ],
      "metadata": {
        "id": "lpf5g7h_BCXN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for traning, validation and test set:\n",
        "convert_id('/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_train.json')\n",
        "convert_id('/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_val.json')\n",
        "convert_id('/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_test.json')"
      ],
      "metadata": {
        "id": "fEwzSRgfBP_8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have voc.yml file: this file have some parameter."
      ],
      "metadata": {
        "id": "a0fLXYyXBwE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(\"/content/gdrive/MyDrive/Colab Notebooks/voc.yml\", \"/content/Yet-Another-EfficientDet-Pytorch/projects\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VdcsftZBBV4j",
        "outputId": "554e50cf-ffbb-45fd-f3aa-60c80646075b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Yet-Another-EfficientDet-Pytorch/projects/voc.yml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#showing its contents here\n",
        "!cat projects/voc.yml "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_40VWhJBzFU",
        "outputId": "9b911c3d-78fb-45b0-bd4e-bac5b9a62a47"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project_name: voc  # also the folder name of the dataset that under data_path folder\r\n",
            "train_set: train\r\n",
            "val_set: val\r\n",
            "num_gpus: 1\r\n",
            "\r\n",
            "# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.\r\n",
            "mean: [ 0.485, 0.456, 0.406 ]\r\n",
            "std: [ 0.229, 0.224, 0.225 ]\r\n",
            "\r\n",
            "# this anchor is adapted to the dataset\r\n",
            "anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\r\n",
            "anchors_ratios: '[(1.0, 1.0), (1.3, 0.8), (1.9, 0.5)]'\r\n",
            "\r\n",
            "obj_list: [ 'aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV.Training: use pre-trained model in COCO dataset\n",
        "\n",
        "Continue training for 15 latter epochs with lr = 1e-3"
      ],
      "metadata": {
        "id": "n61D2Vd0B8vP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ts3-kaANSbBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "db21de37-86d1-4c5e-f38e-7a1a8f5ecbc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Yet-Another-EfficientDet-Pytorch/weights/efficientdet-d0.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# download last checkpoint\n",
        "! mkdir weights\n",
        "shutil.copy(\"/content/gdrive/MyDrive/Colab Notebooks/efficientdet-d0.pth\", \"/content/Yet-Another-EfficientDet-Pytorch/weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training"
      ],
      "metadata": {
        "id": "BkCJP4aPCTmx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AGtMRW0bZsJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30b6b6f-d2d9-424f-de28-a7810a9b7c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "[Info] loaded weights: efficientdet-d0.pth, resuming checkpoint from step: 0\n",
            "[Info] freezed backbone\n",
            "Step: 299. Epoch: 0/15. Iteration: 300/321. Cls loss: 0.25593. Reg loss: 0.88537. Total loss: 1.14130:  93% 299/321 [04:40<00:18,  1.22it/s]checkpoint...\n",
            "Step: 320. Epoch: 0/15. Iteration: 321/321. Cls loss: 0.31762. Reg loss: 1.00795. Total loss: 1.32557: 100% 321/321 [04:57<00:00,  1.08it/s]\n",
            "Val. Epoch: 0/15. Classification loss: 0.37272. Regression loss: 0.98105. Total loss: 1.35377\n",
            "Step: 599. Epoch: 1/15. Iteration: 279/321. Cls loss: 0.25642. Reg loss: 0.91317. Total loss: 1.16958:  87% 278/321 [04:12<00:36,  1.18it/s]checkpoint...\n",
            "Step: 641. Epoch: 1/15. Iteration: 321/321. Cls loss: 0.49247. Reg loss: 1.24126. Total loss: 1.73373: 100% 321/321 [04:46<00:00,  1.12it/s]\n",
            "Val. Epoch: 1/15. Classification loss: 0.36276. Regression loss: 0.96393. Total loss: 1.32669\n",
            "Step: 899. Epoch: 2/15. Iteration: 258/321. Cls loss: 0.34309. Reg loss: 1.05500. Total loss: 1.39809:  80% 257/321 [03:51<00:54,  1.18it/s]checkpoint...\n",
            "Step: 962. Epoch: 2/15. Iteration: 321/321. Cls loss: 0.28820. Reg loss: 0.80783. Total loss: 1.09602: 100% 321/321 [04:43<00:00,  1.13it/s]\n",
            "Val. Epoch: 2/15. Classification loss: 0.29396. Regression loss: 0.96002. Total loss: 1.25398\n",
            "Step: 1199. Epoch: 3/15. Iteration: 237/321. Cls loss: 0.22243. Reg loss: 0.62864. Total loss: 0.85107:  74% 236/321 [03:33<01:12,  1.18it/s]checkpoint...\n",
            "Step: 1283. Epoch: 3/15. Iteration: 321/321. Cls loss: 0.36901. Reg loss: 1.08178. Total loss: 1.45079: 100% 321/321 [04:45<00:00,  1.13it/s]\n",
            "Val. Epoch: 3/15. Classification loss: 0.28594. Regression loss: 0.96021. Total loss: 1.24615\n",
            "Step: 1499. Epoch: 4/15. Iteration: 216/321. Cls loss: 0.23358. Reg loss: 0.95041. Total loss: 1.18399:  67% 215/321 [03:17<01:30,  1.17it/s]checkpoint...\n",
            "Step: 1604. Epoch: 4/15. Iteration: 321/321. Cls loss: 0.27070. Reg loss: 1.31310. Total loss: 1.58380: 100% 321/321 [04:45<00:00,  1.13it/s]\n",
            "Val. Epoch: 4/15. Classification loss: 0.27028. Regression loss: 0.96322. Total loss: 1.23350\n",
            "Step: 1799. Epoch: 5/15. Iteration: 195/321. Cls loss: 0.25884. Reg loss: 1.48264. Total loss: 1.74148:  60% 194/321 [02:57<01:48,  1.17it/s]checkpoint...\n",
            "Step: 1925. Epoch: 5/15. Iteration: 321/321. Cls loss: 0.22331. Reg loss: 1.32273. Total loss: 1.54604: 100% 321/321 [04:44<00:00,  1.13it/s]\n",
            "Val. Epoch: 5/15. Classification loss: 0.26730. Regression loss: 0.96186. Total loss: 1.22916\n",
            "Step: 2099. Epoch: 6/15. Iteration: 174/321. Cls loss: 0.20995. Reg loss: 0.78707. Total loss: 0.99701:  54% 173/321 [02:41<02:06,  1.17it/s]checkpoint...\n",
            "Step: 2246. Epoch: 6/15. Iteration: 321/321. Cls loss: 0.33479. Reg loss: 0.68942. Total loss: 1.02421: 100% 321/321 [04:45<00:00,  1.12it/s]\n",
            "Val. Epoch: 6/15. Classification loss: 0.28006. Regression loss: 0.95643. Total loss: 1.23649\n",
            "Step: 2399. Epoch: 7/15. Iteration: 153/321. Cls loss: 0.28795. Reg loss: 1.13856. Total loss: 1.42650:  47% 152/321 [02:23<02:28,  1.14it/s]checkpoint...\n",
            "Step: 2567. Epoch: 7/15. Iteration: 321/321. Cls loss: 0.23447. Reg loss: 0.79629. Total loss: 1.03076: 100% 321/321 [04:45<00:00,  1.12it/s]\n",
            "Val. Epoch: 7/15. Classification loss: 0.27222. Regression loss: 0.96717. Total loss: 1.23939\n",
            "Step: 2699. Epoch: 8/15. Iteration: 132/321. Cls loss: 0.27566. Reg loss: 0.94438. Total loss: 1.22004:  41% 131/321 [02:03<02:41,  1.17it/s]checkpoint...\n",
            "Step: 2888. Epoch: 8/15. Iteration: 321/321. Cls loss: 0.30201. Reg loss: 1.27892. Total loss: 1.58093: 100% 321/321 [04:45<00:00,  1.13it/s]\n",
            "Val. Epoch: 8/15. Classification loss: 0.26555. Regression loss: 0.96176. Total loss: 1.22732\n",
            "Step: 2999. Epoch: 9/15. Iteration: 111/321. Cls loss: 0.25663. Reg loss: 1.07543. Total loss: 1.33206:  34% 110/321 [01:48<02:59,  1.18it/s]checkpoint...\n",
            "Step: 3209. Epoch: 9/15. Iteration: 321/321. Cls loss: 0.32710. Reg loss: 1.16540. Total loss: 1.49250: 100% 321/321 [04:46<00:00,  1.12it/s]\n",
            "Val. Epoch: 9/15. Classification loss: 0.26285. Regression loss: 0.96541. Total loss: 1.22825\n",
            "Step: 3299. Epoch: 10/15. Iteration: 90/321. Cls loss: 0.36318. Reg loss: 0.98363. Total loss: 1.34681:  28% 89/321 [01:29<03:16,  1.18it/s]checkpoint...\n",
            "Step: 3530. Epoch: 10/15. Iteration: 321/321. Cls loss: 0.27468. Reg loss: 0.94695. Total loss: 1.22163: 100% 321/321 [04:45<00:00,  1.12it/s]\n",
            "Val. Epoch: 10/15. Classification loss: 0.26217. Regression loss: 0.97164. Total loss: 1.23381\n",
            "Step: 3599. Epoch: 11/15. Iteration: 69/321. Cls loss: 0.38978. Reg loss: 1.45366. Total loss: 1.84344:  21% 68/321 [01:12<03:36,  1.17it/s]checkpoint...\n",
            "Step: 3851. Epoch: 11/15. Iteration: 321/321. Cls loss: 0.29434. Reg loss: 1.07402. Total loss: 1.36837: 100% 321/321 [04:47<00:00,  1.12it/s]\n",
            "Val. Epoch: 11/15. Classification loss: 0.26469. Regression loss: 0.97240. Total loss: 1.23709\n",
            "Step: 3899. Epoch: 12/15. Iteration: 48/321. Cls loss: 0.23726. Reg loss: 0.73667. Total loss: 0.97393:  15% 47/321 [00:53<03:53,  1.17it/s]checkpoint...\n",
            "Step: 4172. Epoch: 12/15. Iteration: 321/321. Cls loss: 0.28538. Reg loss: 0.76294. Total loss: 1.04831: 100% 321/321 [04:45<00:00,  1.12it/s]\n",
            "Val. Epoch: 12/15. Classification loss: 0.29694. Regression loss: 0.97324. Total loss: 1.27019\n",
            "Step: 4199. Epoch: 13/15. Iteration: 27/321. Cls loss: 0.21948. Reg loss: 0.89850. Total loss: 1.11798:   8% 26/321 [00:36<04:14,  1.16it/s]checkpoint...\n",
            "Step: 4493. Epoch: 13/15. Iteration: 321/321. Cls loss: 0.26659. Reg loss: 1.19855. Total loss: 1.46513: 100% 321/321 [04:45<00:00,  1.12it/s]\n",
            "Val. Epoch: 13/15. Classification loss: 0.25800. Regression loss: 0.96841. Total loss: 1.22641\n",
            "Step: 4499. Epoch: 14/15. Iteration: 6/321. Cls loss: 0.26901. Reg loss: 1.15659. Total loss: 1.42560:   2% 5/321 [00:19<12:38,  2.40s/it]checkpoint...\n",
            "Step: 4799. Epoch: 14/15. Iteration: 306/321. Cls loss: 0.24131. Reg loss: 1.01146. Total loss: 1.25277:  95% 305/321 [04:39<00:12,  1.28it/s]checkpoint...\n",
            "Step: 4814. Epoch: 14/15. Iteration: 321/321. Cls loss: 0.24405. Reg loss: 0.88991. Total loss: 1.13396: 100% 321/321 [04:51<00:00,  1.10it/s]\n",
            "Val. Epoch: 14/15. Classification loss: 0.26527. Regression loss: 0.96391. Total loss: 1.22918\n"
          ]
        }
      ],
      "source": [
        "!python train.py -c 0 -p voc --head_only True \\\n",
        "                   --lr 1e-3 --batch_size 32 \\\n",
        "                   --load_weights /content/Yet-Another-EfficientDet-Pytorch/weights/efficientdet-d0.pth  --num_epochs 15 --save_interval 300\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we found that the : loss of validation set changes little, so we stop training here."
      ],
      "metadata": {
        "id": "s8LllI2yC6Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V. Evaluation on validation set to find best checkpoint."
      ],
      "metadata": {
        "id": "a6YLuCi-D2uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we just evaluate checkpoints that the loss of validation set < 1.23"
      ],
      "metadata": {
        "id": "wCGmqp4UEAah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ['efficientdet-d0_5_1926.pth', 'efficientdet-d0_8_2700.pth', 'efficientdet-d0_8_2889.pth',\\\n",
        "              'efficientdet-d0_9_3000.pth', 'efficientdet-d0_13_4200.pth', 'efficientdet-d0_13_4494.pth',\\\n",
        "              'efficientdet-d0_14_4800.pth']\n",
        "for filename in checkpoint:\n",
        "  if filename != 'tensorboard':\n",
        "    print('-------------------------------------------------------\\n\\n\\n')\n",
        "    print(filename)\n",
        "\n",
        "    weight_file = filename\n",
        "    !python coco_eval.py -c 0 -p voc -w \"logs/voc/{weight_file}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NRtvpo7DxuR",
        "outputId": "c21043c8-95b3-4350-aba5-726a754190bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_5_1926.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_5_1926.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:26<00:00, 16.55it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.56s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.70s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_8_2700.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_8_2700.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:19<00:00, 17.13it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.74s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=8.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.88s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.657\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708\n",
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_8_2889.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_8_2889.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:20<00:00, 17.09it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.52s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.43s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_9_3000.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_9_3000.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:21<00:00, 17.01it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.506\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_13_4200.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_13_4200.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:21<00:00, 17.01it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.69s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=7.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.81s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.497\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n",
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_13_4494.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_13_4494.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:19<00:00, 17.15it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.38s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.604\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699\n",
            "-------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "efficientdet-d0_14_4800.pth\n",
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_14_4800.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:20<00:00, 17.05it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.55s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.83s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.56s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.513\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can see that: efficientdet-d0_14_4800.pth checkpoint has highest scores."
      ],
      "metadata": {
        "id": "rd4wyKxWbC9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VI. Evaluation on test set:"
      ],
      "metadata": {
        "id": "HE6KevUhEEq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we need to fix format to use EfficientDet tool"
      ],
      "metadata": {
        "id": "dcJ0-UYyENvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/val\n",
        "!mkdir /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/val\n",
        "\n",
        "path = '/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/test'\n",
        "for filename in os.listdir(path):\n",
        "    fullname = os.path.join(path,filename)\n",
        "    shutil.move(fullname, \"/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/val\") "
      ],
      "metadata": {
        "id": "m9sw6hrPDxxJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_val.json\n",
        "\n",
        "old_name = '/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_test.json'\n",
        "new_name = '/content/Yet-Another-EfficientDet-Pytorch/datasets/voc/annotations/instances_val.json'\n",
        "os.rename(old_name, new_name)"
      ],
      "metadata": {
        "id": "Ywg5HoHlQL9K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "\n",
        "weight_file = 'efficientdet-d0_14_4800.pth'\n",
        "!python coco_eval.py -c 0 -p voc -w \"logs/voc/{weight_file}\""
      ],
      "metadata": {
        "id": "7iMz4Uws-u5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ac5604-c893-4a3b-a5b6-8f7142b08ebf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running coco-style evaluation on project voc, weights logs/voc/efficientdet-d0_14_4800.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 3425/3425 [03:24<00:00, 16.78it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.55s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=6.43s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.56s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}